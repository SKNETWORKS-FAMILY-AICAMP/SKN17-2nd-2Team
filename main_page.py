import streamlit as st
import pandas as pd
import joblib
import time
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import matplotlib.font_manager as fm
import matplotlib

# --- í˜ì´ì§€ ì„¤ì • (Streamlit ì•±ì˜ ê°€ì¥ ìƒë‹¨ì— ìœ„ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤) ---
st.set_page_config(
    page_title="ì„œìš¸ì‹œë¯¼ ë„ì„œê´€ ì´ìš©ì ì´íƒˆ ì˜ˆì¸¡",
    page_icon="ğŸ“š", # ì´ëª¨ì§€ ì•„ì´ì½˜ ì¶”ê°€
    layout="wide", # ë ˆì´ì•„ì›ƒì„ wideë¡œ ì„¤ì •
    initial_sidebar_state="expanded"
)

# --- í•œê¸€ í°íŠ¸ ì‚¬ìš©ì„ ìœ„í•œ ì„¤ì • ---
font_path = 'C:/Windows/Fonts/gulim.ttc' # ìœˆë„ìš°ì¦ˆ êµ´ë¦¼ì²´ ê²½ë¡œ
if 'font_loaded' not in st.session_state:
    try:
        font_name = fm.FontProperties(fname=font_path).get_name()
        matplotlib.rc('font', family=font_name)
        matplotlib.rcParams['axes.unicode_minus'] = False # ë§ˆì´ë„ˆìŠ¤ í°íŠ¸ ê¹¨ì§ ë°©ì§€
        st.session_state.font_loaded = True
    except Exception as e:
        st.warning(f"í°íŠ¸ ë¡œë”© ì˜¤ë¥˜: {e}. ê·¸ë˜í”„ì— í•œê¸€ì´ ê¹¨ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        st.session_state.font_loaded = False


# --- ëª¨ë¸ ë¡œë”© ---
@st.cache_resource
def load_churn_model():
    """'final_model.joblib' íŒŒì¼ì„ ë¡œë“œí•˜ëŠ” í•¨ìˆ˜"""
    try:
        model = joblib.load("C:/skn_17/project2/final_model.joblib")
        return model
    except FileNotFoundError:
        st.error("ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. 'C:/skn_17/project2/final_model.joblib' ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return None

model = load_churn_model()


# --- ì…ë ¥ê°’ -> ìˆ«ì ë³€í™˜ì„ ìœ„í•œ ë§µ(Map) ì •ì˜ ---
area_to_group_map = {
    "ê°•ë‚¨êµ¬": 1, "ì„œì´ˆêµ¬": 1, "ì†¡íŒŒêµ¬": 1, "ì¢…ë¡œêµ¬": 1, "ì¤‘êµ¬": 1, "ì˜ë“±í¬êµ¬": 1, "ìš©ì‚°êµ¬": 1,
    "ê°•ë™êµ¬": 2, "ë§ˆí¬êµ¬": 2, "ì„œëŒ€ë¬¸êµ¬": 2, "ì„±ë™êµ¬": 2, "ê´‘ì§„êµ¬": 2, "ë™ì‘êµ¬": 2, "ì–‘ì²œêµ¬": 2,
    "ê°•ë¶êµ¬": 3, "ê´€ì•…êµ¬": 3, "êµ¬ë¡œêµ¬": 3, "ê¸ˆì²œêµ¬": 3, "ë…¸ì›êµ¬": 3, "ë„ë´‰êµ¬": 3, "ë™ëŒ€ë¬¸êµ¬": 3,
    "ì„±ë¶êµ¬": 3, "ì€í‰êµ¬": 3, "ì¤‘ë‘êµ¬": 3
}
job_map = {
    "ë†ì—…, ì–´ì—…, ì„ì—…": 1, "ìì˜ì—…": 2, "íŒë§¤/ì„œë¹„ìŠ¤ì§": 3, "ê¸°ëŠ¥/ìˆ™ë ¨ê³µ": 4,
    "ì¼ë°˜ì‘ì—…ì§": 5, "ì‚¬ë¬´/ê¸°ìˆ ì§": 6, "ê²½ì˜ê´€ë¦¬ì§": 7, "ì „ë¬¸/ììœ ì§": 8,
    "ê°€ì •ì£¼ë¶€": 9, "í•™ìƒ": 10, "êµ¬ì§ì¤‘": 11, "ì€í‡´ì": 12, "ê¸°íƒ€": 13
}
education_map = {"ì´ˆë“±í•™êµ ì¡¸ì—… ì´í•˜": 1, "ì¤‘í•™êµ ì¡¸ì—…": 2, "ê³ ë“±í•™êµ ì¡¸ì—…": 3, "ëŒ€í•™êµ ì¡¸ì—…": 4}
income_map = {
    "100ë§Œì› ë¯¸ë§Œ": 1, "100âˆ¼150ë§Œì› ë¯¸ë§Œ": 2, "150âˆ¼200ë§Œì› ë¯¸ë§Œ": 3,
    "200âˆ¼250ë§Œì› ë¯¸ë§Œ": 4, "250âˆ¼300ë§Œì› ë¯¸ë§Œ": 5, "300âˆ¼350ë§Œì› ë¯¸ë§Œ": 6,
    "350âˆ¼400ë§Œì› ë¯¸ë§Œ": 7, "400âˆ¼450ë§Œì› ë¯¸ë§Œ": 8, "450âˆ¼500ë§Œì› ë¯¸ë§Œ": 9,
    "500âˆ¼550ë§Œì› ë¯¸ë§Œ": 10, "550âˆ¼600ë§Œì› ë¯¸ë§Œ": 11, "600~650ë§Œì› ë¯¸ë§Œ": 12,
    "650~700ë§Œì› ë¯¸ë§Œ": 13, "700ë§Œì› ì´ìƒ": 14
}

# --- í”¼ì²˜ ì¤‘ìš”ë„ ì‹œê°í™” í•¨ìˆ˜ ë° ê´€ë ¨ ì •ì˜ ---
# ëª¨ë¸ í•™ìŠµ ì‹œ ì‚¬ìš©ëœ í”¼ì²˜ ë¦¬ìŠ¤íŠ¸ (hptn4.ipynbì—ì„œ X ì •ì˜ ë¶€ë¶„ê³¼ ë™ì¼í•´ì•¼ í•¨)
numerical_features = ['age', 'income']
categorical_features = ['living_area_grouped', 'job']
ordinal_features = ['gender', 'education', 'experience', 'distance']

# í”¼ì²˜ í•œê¸€ëª… ë§¤í•‘ (ì‹œê°í™”ìš©)
feature_korean_names = {
    'gender': 'ì„±ë³„', 'age': 'ë‚˜ì´', 'education': 'í•™ë ¥', 'income': 'ì†Œë“',
    'job': 'ì§ì—…', 'living_area_grouped': 'ê±°ì£¼ ì§€ì—­', 'experience': 'ì´ìš© ê²½í—˜',
    'distance': 'ê±°ë¦¬'
}

def plot_feature_importances(model, numerical_feats, categorical_feats, ordinal_feats, korean_names_map):
    preprocessor = model.named_steps['preprocessor']
    stacking_classifier = model.named_steps['classifier']

    # ColumnTransformerë¥¼ ê±°ì¹œ í›„ì˜ í”¼ì²˜ ì´ë¦„ ê°€ì ¸ì˜¤ê¸°
    transformed_feature_names = preprocessor.get_feature_names_out()

    # ê° ê¸°ë³¸ ëª¨ë¸ì˜ ì¤‘ìš”ë„ë¥¼ í•©ì‚°í•  ë°°ì—´ ì´ˆê¸°í™”
    aggregated_importances = np.zeros(len(transformed_feature_names))
    num_estimators_contributed = 0 # Initialize a counter for averaging

    # StackingClassifierì˜ ê° ê¸°ë³¸ ëª¨ë¸ì—ì„œ ì¤‘ìš”ë„ ì¶”ì¶œ ë° í•©ì‚°
    for estimator_name, estimator_model in stacking_classifier.named_estimators_.items():
        if hasattr(estimator_model, 'feature_importances_'):
            importances = estimator_model.feature_importances_

            # ê° ëª¨ë¸ì˜ ì¤‘ìš”ë„ í•©ì´ 1ì´ ë˜ë„ë¡ ì •ê·œí™”í•˜ì—¬ ëª¨ë“  ëª¨ë¸ì´ ë™ì¼í•œ ê°€ì¤‘ì¹˜ë¥¼ ê°–ë„ë¡ í•©ë‹ˆë‹¤.
            total_importance = np.sum(importances)
            if total_importance > 0:
                normalized_importances = importances / total_importance
            else:
                normalized_importances = importances # ëª¨ë“  ì¤‘ìš”ë„ê°€ 0ì¸ ê²½ìš° ë°©ì§€

            aggregated_importances += normalized_importances
            num_estimators_contributed += 1 # Increment counter
        else:
            st.write(f"Estimator {estimator_name} does not have feature_importances_ attribute.")

    # ëª¨ë“  ëª¨ë¸ì˜ ì¤‘ìš”ë„ë¥¼ í•©ì‚°í•œ í›„, í‰ê· ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
    if num_estimators_contributed > 0:
        aggregated_importances /= num_estimators_contributed

    # ì„ì‹œ DataFrame ìƒì„±
    temp_df = pd.DataFrame({
        'transformed_feature': transformed_feature_names,
        'importance': aggregated_importances
    })

    # ë³€í™˜ëœ í”¼ì²˜ ì´ë¦„ì„ ì›ë³¸ í”¼ì²˜ ì´ë¦„ìœ¼ë¡œ ë§¤í•‘í•˜ê³  ì¤‘ìš”ë„ ì§‘ê³„
    final_importances = {}
    for _, row in temp_df.iterrows():
        tf_name = row['transformed_feature']
        importance = row['importance']

        original_name = None
        # 'num__', 'cat__', 'ord__' ì ‘ë‘ì‚¬ ì œê±°
        if '__' in tf_name:
            prefix, base_name = tf_name.split('__', 1)
            if prefix in ['num', 'ord']: # ìˆ«ìí˜•, ìˆœì„œí˜• í”¼ì²˜
                original_name = base_name
            elif prefix == 'cat': # ì›-í•« ì¸ì½”ë”©ëœ ë²”ì£¼í˜• í”¼ì²˜
                # ì–´ë–¤ ì›ë³¸ ë²”ì£¼í˜• í”¼ì²˜ì—ì„œ íŒŒìƒë˜ì—ˆëŠ”ì§€ ì°¾ê¸°
                for cat_feat in categorical_feats:
                    if base_name.startswith(f'{cat_feat}_'):
                        original_name = cat_feat
                        break
        else: # ColumnTransformerì— ì˜í•´ ì²˜ë¦¬ë˜ì§€ ì•Šì€ í”¼ì²˜ (ê±°ì˜ ì—†ì„ ê²ƒ)
            original_name = tf_name

        if original_name:
            final_importances[original_name] = final_importances.get(original_name, 0) + importance

    # DataFrameìœ¼ë¡œ ë³€í™˜ ë° ì¤‘ìš”ë„ ìˆœìœ¼ë¡œ ì •ë ¬ (ì˜¤ë¦„ì°¨ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ê·¸ë˜í”„ì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ ê²ƒì´ ìœ„ì— ì˜¤ë„ë¡)
    feature_importance_df = pd.DataFrame(list(final_importances.items()), columns=['feature', 'importance'])
    feature_importance_df = feature_importance_df.sort_values('importance', ascending=True).reset_index(drop=True) # ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬

    # í•œê¸€ ì´ë¦„ìœ¼ë¡œ ë§¤í•‘
    feature_importance_df['feature_korean'] = feature_importance_df['feature'].map(korean_names_map)
    # ë§¤í•‘ë˜ì§€ ì•Šì€ í”¼ì²˜ëŠ” ì›ë³¸ ì´ë¦„ ì‚¬ìš©
    feature_importance_df['feature_korean'].fillna(feature_importance_df['feature'], inplace=True)

    # ì‹œê°í™”
    fig, ax = plt.subplots(figsize=(7, max(2, len(feature_importance_df) * 0.4))) # ë™ì ìœ¼ë¡œ í¬ê¸° ì¡°ì ˆ
    sns.barplot(x='importance', y='feature_korean', data=feature_importance_df, ax=ax, palette='viridis')
    ax.set_title('í”¼ì²˜ ì¤‘ìš”ë„', fontsize=16)
    ax.set_xlabel('ì¤‘ìš”ë„', fontsize=12)
    ax.set_ylabel('í”¼ì²˜', fontsize=12)
    ax.tick_params(axis='x', labelsize=10)
    ax.tick_params(axis='y', labelsize=10)
    plt.tight_layout()
    return fig


# --- ë©”ì¸ ì•± ì‹œì‘ ---
st.title("ğŸ¢ì„œìš¸ì‹œë¯¼ ë„ì„œê´€ ì´ìš©ì ì´íƒˆ ì˜ˆì¸¡ğŸ“š")

tab1, tab2, tab3, tab4 = st.tabs(["1ï¸âƒ£ ê°œìš”", "2ï¸âƒ£ ê°œì¸ ì´íƒˆ ì˜ˆì¸¡", "3ï¸âƒ£ ë‹¨ì²´ ì´íƒˆ ì˜ˆì¸¡", "4ï¸âƒ£ ê²°ê³¼ ë¶„ì„"])

# í˜ì´ì§€ ê°œìš” íƒ­
with tab1:
    st.subheader("")

    c1, c2 = st.columns(2)

    # í˜ì´ì§€ ì„¤ëª… 
    with c1:    
        st.info("""
### âœ”ï¸ í˜ì´ì§€ ì†Œê°œ

ï¸ğŸ—¨ï¸ì´ìš©ìì˜ ì •ë³´, ì´ìš© íŒ¨í„´ ë“±ì„ ì´ìš©í•˜ì—¬ **ì´íƒˆ ì—¬ë¶€ íŒŒì•…**ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.

ï¸ğŸ—¨ï¸ì‹¤ì œ ë„ì„œê´€ ì´ìš© íŒ¨í„´ì„ ë°˜ì˜í•˜ì˜€ê¸° ë•Œë¬¸ì— ì˜ˆì¸¡ ê²°ê³¼ì˜ **ì‹ ë¢°ë„**ë¥¼ ë³´ì¥í•©ë‹ˆë‹¤.

ï¸ğŸ—¨ï¸ë„ì„œê´€ ì„œë¹„ìŠ¤ ê°œì„  ë° ì´ìš©ì ìœ ì§€ ì „ëµ ìˆ˜ë¦½ì— í™œìš© ê°€ëŠ¥í•œ **ì¸ì‚¬ì´íŠ¸**ë¥¼ ë“œë¦½ë‹ˆë‹¤.
""")

    # í˜ì´ì§€ ì‚¬ìš© ë°©ë²•
    with c2:    
        st.info("""
### ğŸ“ ì‚¬ìš© ë°©ë²•


1. ì˜ˆì¸¡í•˜ê³ ì í•˜ëŠ” **ì‚¬ìš©ì ì •ë³´** ì…ë ¥

2. **ì´íƒˆ ì˜ˆì¸¡** ê²°ê³¼ í™•ì¸

3. ì´íƒˆ ì˜ˆì¸¡ì— ëŒ€í•œ **ë¶„ì„ê³¼ ì¸ì‚¬ì´íŠ¸** ìˆ˜ì§‘
""")
        

# =================================================================================

# ì‚¬ìš©ì íŠ¹ì„± íƒ­
with tab2:

    # ì‚¬ìš©ì ê°œì¸ íŠ¹ì„± ì…ë ¥
    st.header("ğŸ’ì‚¬ìš©ì ê°œì¸ íŠ¹ì„±")
    st.caption("")

    col1, col2, col3, col4 = st.columns(4)

    with col1:
        # gender
        gender = st.radio("ì„±ë³„ì„ ì„ íƒí•´ì£¼ì„¸ìš”", ["ë‚¨ì", "ì—¬ì"], horizontal=True)

    with col2:
        # living_area
        living_area = st.selectbox("ì‚¬ëŠ” ì§€ì—­ì„ ì„ íƒí•´ì£¼ì„¸ìš”", list(area_to_group_map.keys()))
    
    with col3:
        # age
        age = st.slider("ë‚˜ì´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”", 10, 100, 35)
    
    with col4:
        # job
        job = st.selectbox("ì§ì—…ì„ ì„ íƒí•´ì£¼ì„¸ìš”", list(job_map.keys()))
    
    st.header("")

    col11, col12, col13, col14 = st.columns(4)

    with col11:
        education = st.radio("í•™ë ¥ì„ ì„ íƒí•´ì£¼ì„¸ìš”", list(education_map.keys()))    

    with col12:
        # income
        income = st.selectbox("ì†Œë“ì„ ì„ íƒí•´ì£¼ì„¸ìš”", list(income_map.keys()))
    
    with col13:
        pass
    st.divider()
    st.caption("")

    st.header("ğŸªªì‚¬ìš©ì ë„ì„œê´€ ì´ìš© íŠ¹ì„±")
    st.caption("")

    col21, col22, col23 = st.columns(3)

    with col21:
        # experience
        experience = st.radio("ë„ì„œê´€ ì´ìš© ê²½í—˜", ["1ë…„ ì•ˆì— ì´ìš©í•¨", "ê³¼ê±°ì—ë§Œ ì´ìš©í•¨"])
    
    with col22:
        # distance
        distance = st.radio("ê±°ì£¼ì§€ì™€ ë„ì„œê´€ì´ ì¸ì ‘í•œê°€ìš”?(ë„ë³´ 20ë¶„ ê¸°ì¤€)", ["ì¸ì ‘í•˜ë‹¤", "ì•„ë‹ˆë‹¤"], horizontal=True)

    st.divider()

    # --- 4. ì˜ˆì¸¡ ë²„íŠ¼ ë° ê²°ê³¼ ì¶œë ¥ ---
    # ì‚¬ìš©ì ë„ì„œê´€ ì´ìš© íŠ¹ì„± ì´ìš©
    st.header("ğŸš€ì´íƒˆ ê°€ëŠ¥ì„± ì˜ˆì¸¡")
    st.caption("")
    if st.button("ì˜ˆì¸¡í•˜ê¸°", use_container_width=True, type="primary"):
        if model:
            # --- ì…ë ¥ê°’ì„ ëª¨ë¸ì´ í•™ìŠµí•œ ë°ì´í„°ì— ì‚¬ìš©í•œ ê°’ê³¼ ë™ì¼í•˜ê²Œ ë³€í™˜ ---
            gender_val = 1 if gender == "ë‚¨ì" else 0
            age_val = age
            education_val = education_map[education]
            income_val = income_map[income]
            job_val = job_map[job]
            living_area_grouped_val = area_to_group_map[living_area]
            experience_val = 1 if experience == "1ë…„ ì•ˆì— ì´ìš©í•¨" else 0
            distance_val = 1 if distance == "ì¸ì ‘í•˜ë‹¤" else 0 # UI í…ìŠ¤íŠ¸ì™€ ì¼ì¹˜ì‹œí‚´

            # --- ëª¨ë¸ ì…ë ¥ì„ ìœ„í•œ ë°ì´í„°í”„ë ˆì„ ìƒì„± ---
            # (ì¤‘ìš”) ì»¬ëŸ¼ ìˆœì„œì™€ ì´ë¦„ì€ ëª¨ë¸ í•™ìŠµ ë•Œ ì‚¬ìš©í•œ ê²ƒê³¼ ì •í™•íˆ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.
            feature_names = ['gender', 'age', 'education', 'income', 'job', 'living_area_grouped', 'experience', 'distance']
            
            input_data = pd.DataFrame([[
                gender_val,
                age_val,
                education_val,
                income_val,
                job_val,
                living_area_grouped_val,
                experience_val,
                distance_val
            ]], columns=feature_names)

            # --- ì˜ˆì¸¡ ì‹¤í–‰ ë° ê²°ê³¼ í‘œì‹œ ---
            with st.spinner("AI ëª¨ë¸ì´ ì´íƒˆ í™•ë¥ ì„ ê³„ì‚°í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
                time.sleep(1) # ë¡œë”©í•˜ëŠ” ê²ƒì²˜ëŸ¼ ë³´ì´ê²Œ ì ì‹œ ëŒ€ê¸°
                
                try:
                    # 1. decision_functionìœ¼ë¡œ í™•ì‹  ì ìˆ˜(score)ë¥¼ ì–»ìŒ
                    decision_score = model.decision_function(input_data)

                    # 2. ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜ë¥¼ ì ìš©í•˜ì—¬ ì ìˆ˜ë¥¼ 0~1 ì‚¬ì´ì˜ í™•ë¥  ê°™ì€ ê°’ìœ¼ë¡œ ë³€í™˜
                    def sigmoid(x):
                        return 1 / (1 + np.exp(-x))
                    
                    churn_probability = sigmoid(decision_score[0])

                except AttributeError:
                    st.error("ëª¨ë¸ì— decision_functionì´ ì—†ìŠµë‹ˆë‹¤. ëª¨ë¸ì´ ì˜ëª» ì €ì¥ë˜ì—ˆê±°ë‚˜ RidgeClassifierê°€ ì•„ë‹™ë‹ˆë‹¤.")
                    st.stop() # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì¤‘ë‹¨


            st.header("ì´íƒˆ ê°€ëŠ¥ì„± ì˜ˆì¸¡ ê²°ê³¼")
            
            # í™•ë¥ ì— ë”°ë¼ ë‹¤ë¥¸ ë©”ì‹œì§€ í‘œì‹œ
            if churn_probability > 0.5: # ì„ê³„ê°’ì€ í•„ìš”ì— ë”°ë¼ ì¡°ì • ê°€ëŠ¥
                st.error(f"ì´íƒˆ í™•ë¥ ì´ **{churn_probability:.2%}** ë¡œ, **'ì´íƒˆ ì˜ˆìƒ'** íšŒì›ì…ë‹ˆë‹¤.")
            else:
                st.success(f"ì´íƒˆ í™•ë¥ ì´ **{churn_probability:.2%}** ë¡œ, **'ì”ë¥˜ ì˜ˆìƒ'** íšŒì›ì…ë‹ˆë‹¤.")
            
            # í™•ë¥ ì„ í”„ë¡œê·¸ë ˆìŠ¤ ë°”ë¡œ ì‹œê°í™”
            st.progress(churn_probability, text=f"ì´íƒˆ í™•ë¥ : {churn_probability:.0%}")

        else:
            st.error("ëª¨ë¸ì„ ë¡œë“œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. íŒŒì¼ ê²½ë¡œë¥¼ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.")

    st.caption("")

# =================================================================================

# ê²°ê³¼ ë¶„ì„ íƒ­
with tab4:
    st.header("ğŸ«§ì‚¬ìš©ì ì´íƒˆ ì˜ˆì¸¡ ë¶„ì„")

    coll1, coll2 = st.columns(2)

    with coll1:

        if model:
            st.subheader("â¬‡ï¸ í”¼ì²˜ ì¤‘ìš”ë„ ë¶„ì„")
            st.write("âš–ï¸ ëª¨ë¸ì´ ì´íƒˆ ì˜ˆì¸¡ì— ì‚¬ìš©í•œ ê° í”¼ì²˜ì˜ ìƒëŒ€ì  ì¤‘ìš”ë„ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤. ")
            
            # í”¼ì²˜ ì¤‘ìš”ë„ ê·¸ë˜í”„ ìƒì„± ë° í‘œì‹œ
            fig_importance = plot_feature_importances(model, numerical_features, categorical_features, ordinal_features, feature_korean_names)
            st.pyplot(fig_importance)
        else:
            st.warning("ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•„ í”¼ì²˜ ì¤‘ìš”ë„ë¥¼ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# ë°ì´í„°ì…‹ ë¶„ì„ íƒ­
with tab3:
    st.header("ğŸ“Š ë°ì´í„°ì…‹ ê¸°ë°˜ ì´íƒˆ ë¶„ì„")
    st.write("ì´íƒˆ ì—¬ë¶€ ì˜ˆì¸¡ì— ì‚¬ìš©ëœ í”¼ì²˜ë“¤ì´ ê° ê·¸ë£¹ë³„ë¡œ ì–´ëŠ ì •ë„ì˜ ì´íƒˆ ìœ„í—˜ë„ë¥¼ ë³´ì´ëŠ”ì§€ ì‹œê°ì ìœ¼ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.")
    
    uploaded_file = st.file_uploader("ë¶„ì„í•  CSV íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.", type="csv")

    if uploaded_file is not None:
        try:
            df_preview = pd.read_csv(uploaded_file)
            st.write("##### âœ”ï¸ ì—…ë¡œë“œëœ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° (ìƒìœ„ 5ê°œ)")
            st.dataframe(df_preview.head())

            if st.button("ë°ì´í„°ì…‹ ë¶„ì„ ì‹œì‘", use_container_width=True, type="primary"):
                if model:
                    with st.spinner("AI ëª¨ë¸ì´ ë°ì´í„°ì…‹ ì „ì²´ì˜ ì´íƒˆ í™•ë¥ ì„ ê³„ì‚° ì¤‘ì…ë‹ˆë‹¤... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”."):
                        # --- ë°ì´í„° ì „ì²˜ë¦¬ ë° ì˜ˆì¸¡ ---
                        df_analysis = df_preview.copy()
                        
                        required_cols = ['gender', 'age', 'education', 'income', 'job', 'living_area_grouped', 'experience', 'distance']
                        if not all(col in df_analysis.columns for col in required_cols):
                            missing_cols = [col for col in required_cols if col not in df_analysis.columns]
                            st.error(f"ì˜¤ë¥˜: ì—…ë¡œë“œëœ CSV íŒŒì¼ì— í•„ìˆ˜ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: **{', '.join(missing_cols)}**")
                            st.stop()

                        df_model_input = df_analysis[required_cols]
                        
                        decision_scores = model.decision_function(df_model_input)
                        churn_probabilities = 1 / (1 + np.exp(-decision_scores))
                        df_analysis['churn_probability'] = churn_probabilities
                        
                        bins = [20, 30, 40, 50, 60, 70, 101]
                        labels = ['20ëŒ€', '30ëŒ€', '40ëŒ€', '50ëŒ€', '60ëŒ€', '70ëŒ€ ì´ìƒ']
                        df_analysis['age_group'] = pd.cut(df_analysis['age'], bins=bins, labels=labels, right=False)
                        
                    st.success("ë°ì´í„°ì…‹ ë¶„ì„ ì™„ë£Œ!")

                    # --- ì „ì²´ í‰ê·  ì´íƒˆ í™•ë¥  ---
                    overall_churn_prob = df_analysis['churn_probability'].mean()
                    st.metric(label="ğŸ“ˆ ì „ì²´ ë°ì´í„°ì…‹ í‰ê·  ì´íƒˆ í™•ë¥ ", value=f"{overall_churn_prob:.2%}")
                    st.divider()

                    # --- í”¼ì²˜ë³„ ì‹œê°í™” ---
                    st.subheader("ğŸ” í”¼ì²˜ë³„ ì´íƒˆ ìœ„í—˜ë„ ìƒì„¸ ë¶„ì„")

                    # ë¶„ì„í•  í”¼ì²˜ì™€ ì—­ë³€í™˜ ë§µ ì •ì˜
                    features_to_plot = {
                        'age_group': 'ë‚˜ì´ëŒ€', 'living_area_grouped': 'ê±°ì£¼ ì§€ì—­ ê·¸ë£¹', 'income': 'ì†Œë“ ìˆ˜ì¤€',
                        'job': 'ì§ì—…', 'education': 'í•™ë ¥', 'gender': 'ì„±ë³„',
                        'experience': 'ìµœê·¼ ì´ìš© ê²½í—˜', 'distance': 'ë„ì„œê´€ ì¸ì ‘ì„±'
                    }
                    reverse_maps = {
                        'gender': {0: "ì—¬ì", 1: "ë‚¨ì"}, 'education': {v: k for k, v in education_map.items()},
                        'income': {v: k for k, v in income_map.items()}, 'job': {v: k for k, v in job_map.items()},
                        'experience': {0: "ê³¼ê±°ì—ë§Œ ì´ìš©", 1: "1ë…„ ë‚´ ì´ìš©"}, 'distance': {0: "ì¸ì ‘ ì•ˆ í•¨", 1: "ì¸ì ‘í•¨"},
                        'living_area_grouped': {1: "1ê·¸ë£¹(í•µì‹¬)", 2: "2ê·¸ë£¹(ì£¼ê±°)", 3: "3ê·¸ë£¹(ì™¸ê³½)"}
                    }

                    feature_keys = list(features_to_plot.keys())

                    # í”¼ì²˜ ë¦¬ìŠ¤íŠ¸ë¥¼ 2ê°œì”© ë¬¶ì–´ ë°˜ë³µ ì²˜ë¦¬
                    for i in range(0, len(feature_keys), 2):
                        cols = st.columns(2)
                        
                        # ì²« ë²ˆì§¸ ì»¬ëŸ¼ ê·¸ë˜í”„
                        feature1_key = feature_keys[i]
                        with cols[0]:
                            churn_by_feature = df_analysis.groupby(feature1_key)['churn_probability'].mean().sort_values(ascending=False)
                            if feature1_key in reverse_maps:
                                churn_by_feature.index = churn_by_feature.index.map(reverse_maps[feature1_key].get)
                            
                            fig, ax = plt.subplots()
                            sns.barplot(x=churn_by_feature.index, y=churn_by_feature.values, ax=ax, palette='viridis', order=churn_by_feature.index)
                            ax.set_title(f'{features_to_plot[feature1_key]}ë³„ í‰ê·  ì´íƒˆ í™•ë¥ ', fontsize=14)
                            ax.set_ylabel('í‰ê·  ì´íƒˆ í™•ë¥ ', fontsize=10)
                            ax.set_xlabel('')
                            ax.tick_params(axis='x', rotation=45, labelsize=9)
                            ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: f'{y:.0%}'))
                            plt.tight_layout()
                            st.pyplot(fig)
                            if feature1_key == 'living_area_grouped':
                                st.caption("1(í•µì‹¬), 2(ì£¼ê±°), 3(ì™¸ê³½)")

                        # ë‘ ë²ˆì§¸ ì»¬ëŸ¼ ê·¸ë˜í”„ (í”¼ì²˜ê°€ í™€ìˆ˜ ê°œì¼ ê²½ìš°ë¥¼ ëŒ€ë¹„)
                        if i + 1 < len(feature_keys):
                            feature2_key = feature_keys[i+1]
                            with cols[1]:
                                churn_by_feature = df_analysis.groupby(feature2_key)['churn_probability'].mean().sort_values(ascending=False)
                                if feature2_key in reverse_maps:
                                    churn_by_feature.index = churn_by_feature.index.map(reverse_maps[feature2_key].get)

                                fig, ax = plt.subplots()
                                sns.barplot(x=churn_by_feature.index, y=churn_by_feature.values, ax=ax, palette='viridis', order=churn_by_feature.index)
                                ax.set_title(f'{features_to_plot[feature2_key]}ë³„ í‰ê·  ì´íƒˆ í™•ë¥ ', fontsize=14)
                                ax.set_ylabel('í‰ê·  ì´íƒˆ í™•ë¥ ', fontsize=10)
                                ax.set_xlabel('')
                                ax.tick_params(axis='x', rotation=45, labelsize=9)
                                ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda y, _: f'{y:.0%}'))
                                plt.tight_layout()
                                st.pyplot(fig)
                                if feature2_key == 'living_area_grouped':
                                    st.caption("1(í•µì‹¬), 2(ì£¼ê±°), 3(ì™¸ê³½)")

                else:
                    st.error("ëª¨ë¸ì„ ë¡œë“œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.")
        except Exception as e:
            st.error(f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")